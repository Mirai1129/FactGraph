"""
answerer â”€ å•ç­”ä¸»æµç¨‹ï¼ˆOrchestratorï¼‰

è·è²¬åªåšã€Œæµç¨‹å”èª¿ã€ï¼Œä¸è™•ç†ç¹é›œæ¥­å‹™é‚è¼¯ï¼š
0. python -m src.qa.answerer.pipeline
1. è®€å–ä½¿ç”¨è€…å•é¡Œï¼ˆæª”æ¡ˆæˆ– stdinï¼‰ä¸¦å–å¾— slug
2. å‘¼å« GPT æŠ½å–ä¸‰å…ƒçµ„
3. ä»¥å‘é‡æœå°‹ KG ç›¸é—œæ•˜è¿°
4. å»é‡ï¼ˆç›¸ä¼¼åƒ…ä¿ç•™æœ€é•·æ¢ç›®ï¼‰
5. å‘¼å« GPT è©•ä¼°æœ€çµ‚çµæœ
6. ä¾è¼¸å…¥æª”åå‹•æ…‹è¼¸å‡º user_kg_*.txt èˆ‡ user_qa_judge_*.txt
"""

from __future__ import annotations

import os
import sys
from pathlib import Path
from typing import List, Dict

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ æœ¬å°ˆæ¡ˆè‡ªè£½æ¨¡çµ„ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
from .core.paths import (
    CKIP_ROOT,
    KG_EMB_PATH,
    KG_CSV_PATH,
    OUT_DIR,
    USER_INPUT_DIR,
    EXTRACT_PROMPT_PATH,
    JUDGE_PROMPT_PATH,
)
from .core.embedding import load_embedder, embed_triple, embed_text, dedupe
from .core.utils import read_question, safe_json_loads, clean_json_block
from .kg.loader import load_kg_vectors, load_kg_df
from .kg.search import search_by_triples
from .llm.gpt import GPTClient
from .llm.prompt_loader import load_prompt

# éœ€ç”¨åˆ° qa.tools ç”Ÿæˆæ•˜è¿°å€å¡Š
from ..tools import kg_nl as knl
from ..tools import data_utils as du

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ åƒæ•¸è¨­å®š â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
SIM_TH: float = 0.80          # KG ç›¸ä¼¼åº¦é–€æª»
TOP_K: int = 100              # æ¯å€‹ä¸‰å…ƒçµ„å–å‰ TOP_K æ¢

# ---------------------------------------------------------------------------
# ä¸»æµç¨‹
# ---------------------------------------------------------------------------


def main() -> None:
    """æ•´å€‹å•ç­”ç®¡ç·šçš„å…¥å£å‡½å¼ã€‚"""

    # ========== 1. è³‡æºåˆå§‹åŒ– ==========
    # 1-1 å¥å‘é‡æ¨¡å‹
    emb = load_embedder(CKIP_ROOT)

    # 1-2 KG å‘é‡èˆ‡ DataFrame
    kg_vecs, kg_vecs_norm = load_kg_vectors(KG_EMB_PATH)
    kg_df, hp_col, rp_col, tp_col = load_kg_df(KG_CSV_PATH)

    # 1-3 Prompt èˆ‡ GPT client
    extract_prompt: str = load_prompt(EXTRACT_PROMPT_PATH)
    judge_prompt: str = load_prompt(JUDGE_PROMPT_PATH)

    gpt = GPTClient(
        api_key=os.getenv("GPT_API"),
        model_id=os.getenv("GPT_MODEL", "gpt-4o"),
        temperature=0.4,
        top_p=0.9,
        max_tokens=2048,
    )

    # ========== 2. è®€å–ä½¿ç”¨è€…å•é¡Œ ==========
    question, slug = read_question(USER_INPUT_DIR)
    print(f"ğŸ”¸ Question: {question}")

    # ========== 3. å‘¼å« GPT æŠ½å–ä¸‰å…ƒçµ„ ==========
    raw_resp: str = gpt.chat(extract_prompt, question)
    print("ğŸªµ GPT raw response:\n", raw_resp)

    # æ¸…ç† fence â†’ JSON è§£æ
    cleaned = clean_json_block(raw_resp)
    data = safe_json_loads(cleaned)

    # å…¼å®¹å…©ç¨® schema
    if isinstance(data, dict) and "triples" in data:
        triples: List[Dict[str, str]] = [
            {
                "head": t.get("subject"),
                "relation": t.get("relation"),
                "tail": t.get("object"),
            }
            for t in data["triples"]
            if t.get("subject") and t.get("relation")
        ]
    else:
        triples = du.json_to_triples(data) or []

    print(f"ğŸª² Parsed triples count: {len(triples)}")
    if not triples:
        sys.exit("âŒ GPT æœªæŠ½å–åˆ°ä¸‰å…ƒçµ„")

    # ========== 4. KG å‘é‡æª¢ç´¢ ==========
    raw_lines = search_by_triples(
        triples,
        embed_fn=lambda tp: embed_triple(emb, tp),
        kg_vecs_norm=kg_vecs_norm,
        top_k=TOP_K,
        sim_th=SIM_TH,
        kg_df=kg_df,
        hp_col=hp_col,
        rp_col=rp_col,
        tp_col=tp_col,
        build_block_fn=knl.build_block,
    )
    if not raw_lines:
        sys.exit("âš ï¸  KG ç„¡ä»»ä½•åŒ¹é…")

    # ========== 5. èªæ„å»é‡ï¼ˆç›¸ä¼¼ä¿ç•™æœ€é•·ï¼‰==========
    final_lines = dedupe(
        raw_lines,
        embed_fn=lambda ln: embed_text(emb, ln),
        threshold=0.80,
    )

    # ========== 6. ä¾ slug å‹•æ…‹è¼¸å‡º ==========
    OUT_DIR.mkdir(parents=True, exist_ok=True)
    kg_out: Path = OUT_DIR / f"user_kg_{slug}.txt"
    judge_out: Path = OUT_DIR / f"user_qa_judge_{slug}.txt"

    kg_out.write_text(
        "```\n[ä½¿ç”¨è€…æå•]\n"
        f"{question}\n```\n"
        "```\n[çŸ¥è­˜æŸ¥è©¢çµæœ]\n"
        + "\n".join(final_lines)
        + "\n```",
        encoding="utf-8",
    )

    # ========== 7. GPT æœ€çµ‚åˆ¤æ–· ==========
    judge_result = gpt.chat(judge_prompt, kg_out.read_text(encoding="utf-8"))
    judge_out.write_text(judge_result, encoding="utf-8")

    print("âœ… finished; outputs saved under", OUT_DIR)
    print("   KG    â†’", kg_out.name)
    print("   JUDGE â†’", judge_out.name)


# ---------------------------------------------------------------------------
# CLI åŸ·è¡Œ
# ---------------------------------------------------------------------------

if __name__ == "__main__":
    main()
