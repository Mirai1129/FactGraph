#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Embedding helpers (CKIP-SBERT) with dedupe functionality.

æä¾›ï¼š
 - load_embedder: è¼‰å…¥ SentenceTransformer æ¨¡å‹
 - embed_text: å°‡æ–‡å­—è½‰ç‚ºå–®ä½å‘é‡
 - embed_triple: å°‡ä¸‰å…ƒçµ„è½‰ç‚ºæ–‡å­—å¾ŒåµŒå…¥
 - dedupe: ä»¥å¯¦é«”å‰ç¶´åˆ†çµ„ï¼Œä¿ç•™èªç¾©æœ€é•·ï¼Œä¸¦é‡ç·¨è™Ÿ
"""

from __future__ import annotations

import re
from pathlib import Path
from typing import List, Callable

import numpy as np
from sentence_transformers import SentenceTransformer, util

# Regex patterns
ENTITY_PATTERN = re.compile(r"^\d+\.\s*([^\sï¼ˆ]+)")
NUMBERING_PATTERN = re.compile(r"^(?:\[\d+\]\.|\d+\.)\s*")


def _resolve_snapshot(root: Path) -> Path:
    """æ‰¾åˆ°åŒ…å« config.json èˆ‡æ¨¡å‹æ¬Šé‡çš„å¿«ç…§ç›®éŒ„"""
    root = root.expanduser()
    # ç›´æ¥åœ¨ root ç›®éŒ„ä¸‹
    if (root / 'config.json').is_file() and any(
            (root / ext).is_file() for ext in [
                'pytorch_model.bin', 'model.safetensors', 'tf_model.h5',
                'model.ckpt.index', 'flax_model.msgpack'
            ]
    ):
        return root

    # åœ¨ snapshots å­ç›®éŒ„ä¸­å°‹æ‰¾
    snapshots = root / 'snapshots'
    if snapshots.is_dir():
        for cand in snapshots.iterdir():
            if (cand / 'config.json').is_file() and any(
                    (cand / ext).is_file() for ext in [
                        'pytorch_model.bin', 'model.safetensors', 'tf_model.h5',
                        'model.ckpt.index', 'flax_model.msgpack'
                    ]
            ):
                return cand

    raise FileNotFoundError(f'æ‰¾ä¸åˆ°æœ‰æ•ˆæ¨¡å‹å¿«ç…§æ–¼ {root}')


def load_embedder(model_root: Path, device: str | None = None) -> SentenceTransformer:
    """è¼‰å…¥ CKIP-SBERT æ¨¡å‹ä¸¦å›å‚³ embedder"""
    resolved = _resolve_snapshot(model_root)
    import torch
    device = device or ('cuda' if torch.cuda.is_available() else 'cpu')
    print(f'ğŸ”§ è¼‰å…¥ CKIP-SBERT: {resolved} (device={device})', flush=True)
    return SentenceTransformer(str(resolved), device=device, trust_remote_code=True)


def embed_text(emb: SentenceTransformer, text: str) -> np.ndarray:
    """å°‡æ–‡å­—åµŒå…¥ä¸¦å›å‚³å–®ä½å‘é‡"""
    vec = emb.encode(text, convert_to_numpy=True, show_progress_bar=False)
    norm = np.linalg.norm(vec)
    return vec / norm if norm else vec


def embed_triple(emb: SentenceTransformer, tp: dict[str, str]) -> np.ndarray:
    """å°‡ä¸‰å…ƒçµ„å­—å…¸æ‹¼æ¥å¾ŒåµŒå…¥"""
    head = tp.get('head', '')
    rel = tp.get('relation', '')
    tail = tp.get('tail', '')
    return embed_text(emb, f"{head} {rel} {tail}")


def dedupe(
        lines: List[str],
        embed_fn: Callable[[str], np.ndarray],
        threshold: float
) -> List[str]:
    """
    ä¾ç¬¬ä¸€å¯¦é«”åˆ†æ¡¶ï¼ŒåŒä¸€æ¡¶å…§è‹¥ç›¸ä¼¼åº¦ >= threshold è¦–ç‚ºé‡è¤‡ï¼Œ
    åªä¿ç•™æœ€é•·æ•˜è¿°ï¼Œæœ€å¾Œé‡ç·¨è™Ÿã€‚
    """
    groups: dict[str, list[tuple[str, np.ndarray]]] = {}
    order: list[str] = []

    for line in lines:
        m = ENTITY_PATTERN.match(line)
        key = m.group(1) if m else line.split()[0]
        vec = embed_fn(line)

        bucket = groups.setdefault(key, [])
        replaced = False
        for idx, (existing, existing_vec) in enumerate(bucket):
            if util.cos_sim(vec, existing_vec).item() >= threshold:
                if len(line) > len(existing):
                    bucket[idx] = (line, vec)
                    pos = order.index(existing)
                    order[pos] = line
                replaced = True
                break

        if not replaced:
            bucket.append((line, vec))
            order.append(line)

    # é‡ç·¨è™Ÿä¸¦ç§»é™¤åŸæœ‰ç·¨è™Ÿ
    result: list[str] = []
    for i, original in enumerate(order, start=1):
        without_num = NUMBERING_PATTERN.sub('', original)
        result.append(f'[{i}] {without_num}')

    return result
